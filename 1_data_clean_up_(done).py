# -*- coding: utf-8 -*-
"""1. Data Clean Up (Done)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tSPXs_A7wiSi2BNYCld_xZLdq2rOTL5D
"""

# REMEMBER TO SAVE BEFORE CLOSING

# Commented out IPython magic to ensure Python compatibility.
# link your google drive. You'll have to do this everytime you open up the notebook or reset the run time.

from google.colab import drive

drive.mount('/content/gdrive/', force_remount=True)

# the easiest way to access a shared google folder is to add the shared folder as a short cut into your drive
# find "Erdos_project" folder that Kim shared, right click, click on organize, then click on add shortcut

# %cd gdrive/MyDrive/Erdos_project

# if you get this error: [Errno 107] Transport endpoint is not connected: 'gdrive/MyDrive' /content/gdrive/MyDrive
# then go to "Runtime" at the top, and click "restart runtime"

# load the data in
# OTU table: Soybean_OTU.tsv
# soil nutrient data: soil_nutrient_data.xlsx
import os

# get the current working directory
current_working_directory = os.getcwd()

# print output to the console
print(current_working_directory)


import pandas as pd

otu = pd.read_csv('soybean_otu_taxonomy.csv',sep=' ')

otu.head()

# Get the dimensions
num_rows, num_columns = otu.shape

# Print the dimensions
print(f"Number of rows: {num_rows}")
print(f"Number of columns: {num_columns}")

# Filter based on Family and Class criteria

# in R, there are 3 otu that match to mitochondria and 8 that match to chlorplast. Therefore, number of rows should go from 4978 - 11 = 4967
otu_table = otu[~((otu['Family'] == 'Mitochondria') | (otu['Order'] == 'Chloroplast'))]

# Get the dimensions
num_rows, num_columns = otu_table.shape

# Print the dimensions
print(f"Number of rows: {num_rows}")
print(f"Number of columns: {num_columns}")

# Calculate the number of samples with at least 10 reads for each OTU
selected_columns = otu_table.iloc[:, list(range(7, 19))]

selected_columns.head()

# Get the dimensions
num_rows, num_columns = selected_columns.shape

# Print the dimensions
print(f"Number of rows: {num_rows}")
print(f"Number of columns: {num_columns}")

"""Number of samples is 12, so columns should be 12"""

# Remove samples with less than 100 reads
otu_table = selected_columns.loc[:, selected_columns.sum() >= 100]

otu_table.head()

# Get the dimensions
num_rows, num_columns = otu_table.shape

# Print the dimensions
print(f"Number of rows: {num_rows}")
print(f"Number of columns: {num_columns}")

# Remove counts/taxa with less than 0.5% abundance in any sample
threshold = 0.005 * otu_table.sum(axis=1)
otu_table = otu_table.loc[otu_table.sum(axis=1) >= threshold]

# Remove doubletons and singletons
otu_table = otu_table.loc[otu_table.apply(lambda x: (x > 0).sum() > 1, axis=1)]

otu_table.head()

# Get the dimensions
otu_table_rows, otu_table_columns = otu_table.shape

# Print the dimensions
print(f"Number of rows: {otu_table_rows}")
print(f"Number of columns: {otu_table_columns}")

# taxonomy table

taxa_columns = otu.iloc[:, 1:7]

taxa_columns.head()

# Get the dimensions
taxa_columns_rows, taxa_columns_columns = taxa_columns.shape

# Print the dimensions
print(f"Number of rows: {taxa_columns_rows}")
print(f"Number of columns: {taxa_columns_columns}")

# get the row names
otu_row_names = otu_table.index

print(otu_row_names)

otu_table.head()

taxa_filter = taxa_columns.loc[otu_table.index, :]  # works

taxa_filter.head()

merged_df = pd.concat([taxa_filter, otu_table], axis=1)

merged_df.head()

# Get the dimensions
merge_rows, merge_columns = merged_df.shape

# Print the dimensions
print(f"Number of rows: {merge_rows}")
print(f"Number of columns: {merge_columns}")

# Save the filtered OTU table if needed
merged_df.to_csv('filtered_otu_table.csv')